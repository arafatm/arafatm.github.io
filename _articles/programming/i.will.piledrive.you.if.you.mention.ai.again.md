---
categories: programming
created: 2024-07-02T19:17:23 (UTC -07:00)
tags: ai humor
source: https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/
author: ludicity
title: Eponymous Laws Part I - Laws of the Internet
---


> The recent innovations in the AI space, most notably those such as GPT-4, obviously have far-reaching implications for society, ranging from the utopian eliminating of drudgery, to the dystopian damage to the livelihood of artists in a capitalist society, to existential threats to humanity itself.

---

The recent innovations in the AI space, most notably those such as GPT-4, obviously have far-reaching implications for society, ranging from the utopian eliminating of drudgery, to the dystopian damage to the livelihood of artists in a capitalist society, to existential threats to humanity itself.

I myself have formal training as a data scientist, [going so far as to dominate a competitive machine learning event at one of Australia's top universities](https://ludic.mataroa.blog/blog/breaking-my-universitys-machine-learning-competition/) and writing a Master's thesis where I wrote all my own libraries from scratch in MATLAB. I'm not God's gift to the field, but I am _clearly_ better than most of my competition - that is, practitioners like myself who haven't put in the reps to build their own C libraries in a cave with scraps, but can read textbooks, implement known solutions in high-level languages, and use libraries written by elite institutions.

So it is with great regret that I announce that the next person to talk about rolling out AI is going to receive a complimentary chiropractic adjustment in the style of Dr. Bourne, i.e, I am going to fucking break your neck. I am truly, deeply, sorry.

## I. But We Will Realize Untold Efficiencies With Machine L-

What the _fuck_ did I just say?

I started working as a data scientist in 2019, and by 2021 I had realized that while the field was _large_, it was also _large_ly fraudulent. Most of the leaders that I was working with clearly had not gotten as far as reading about it for thirty minutes despite insisting that things like, I dunno, the next five years of a ten thousand person non-tech organization should be entirely AI focused. The number of companies launching AI initiatives far outstripped the number of _actual_ use cases. Most of the market was simply grifters and incompetents (sometimes both!) leveraging the hype to inflate their headcount so they could get promoted, or be seen as thought leaders<sup id="fnref:1"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:1">1</a></sup>.

The money was phenomenal, but I nonetheless fled for the safer waters of data and software engineering. You see, while hype is _nice_, it's only nice in small bursts for _practitioners_. We have a few key things that a grifter does not have, such as job stability, genuine friendships, and _souls_. What we do _not_ have is the ability to trivially switch fields the moment the gold rush is over, due to the sad fact that we actually need to study things and build experience. Grifters, on the other hand, wield the omnitool that they self-aggrandizingly call 'politics'<sup id="fnref:2"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:2">2</a></sup>. That is to say, it turns out that the core competency of smiling and promising people things that you can't actually deliver is _highly transferable_.

I left the field, as did most of my smarter friends, and my salary continued to rise a reasonable rate and _sustainably_ as I learned the wisdom of our ancient forebearers. You can hear it too, on freezing nights under the pale moon, when the fire burns low and the trees loom like hands of sinister ghosts all around you - when the wind cuts through the howling of what you _hope_ is a wolf and hair stands on end, you can strain your ears and barely make out:

"Just Use Postgres, You Nerd. You Dweeb."

The data science jobs began to evaporate, and the hype cycle moved on from all those AI initiatives which failed to make any progress, and started to inch towards data engineering. This was a signal that I had both predicted correctly _and_ that it would be time to move on soon. At least, I thought, all that AI stuff was finally done, and we might move on to actually getting something accomplished.

And then some absolute son of a bitch created ChatGPT, and _now look at us_. _Look at us_, resplendent in our pauper's robes, stitched from corpulent greed and breathless credulity, spending half of the planet's engineering efforts to add chatbot support to every application under the sun when half of the industry hasn't worked out how to test database backups regularly. This is why I have to visit untold violence upon the next moron to propose that AI is the future of the business - not because this is impossible _in principle_, but because they are now _indistinguishable_ from a hundred million willful fucking idiots.

## II. But We Need AI To Remain Comp-

Sweet merciful Jesus, stop talking. Unless you are one of a tiny handful of businesses who know _exactly_ what they're going to use AI for, you _do not need AI for anything_ - or rather, you do not need to do anything to reap the benefits. Artificial intelligence, as it exists and is useful now, is probably _already_ baked into your businesses software supply chain. Your managed security provider is probably using some algorithms baked up in a lab software to detect anomalous traffic, and here's a secret, _they didn't do much AI work either_, they bought software from the tiny sector of the market that actually _does_ need to do employ data scientists. I know you want to be the next Steve Jobs, and this requires you to get on stages and talk about your innovative prowess, but none of this will allow you to pull off a turtle neck, and even if it _did_, you would need to replace your sweaters with fullplate to survive my onslaught.

Consider the fact that most companies are unable to successfully develop and deploy the simplest of CRUD applications on time and under budget. This is a _solved problem_ - with smart people who can collaborate and provide reasonable requirements, a competent team will knock this out of the park _every single time_, admittedly with some amount of frustration. The clients I work with now are all like this - even if they are totally non-technical, we have a mutual respect for the other party's intelligence, and then we do this crazy thing where we _solve problems together_. I may not know anything about the nuance of building analytics systems for drug rehabilitation research, but through the power of _talking to each other like adults_, we somehow solve problems.

But most companies can't do this, because they are operationally and culturally crippled. The median stay for an engineer will be something between one to two years, so the organization suffers from institutional retrograde amnesia. Every so often, some dickhead says something like "Maybe we should revoke the engineering team's remote work privile - whoa, wait, why did all the best engineers leave?". Whenever there is a ransomware attack, it is revealed with clockwork precision that no one has tested the backups for six months and half the legacy systems cannot be resuscitated - something that I have personally seen _twice_ in _four fucking years_. Do you know how _insane_ that is?

Most organizations cannot ship the most basic applications imaginable with any consistency, and you're out here saying that the best way to remain competitive is to roll out _experimental technology_ that is an order of magnitude more sophisticated than anything else your I.T department runs, which you have no experience hiring for, when the organization has _never_ used a GPU for anything other than junior engineers playing video games with their camera off during standup, and _even if you do that all right_ there is a chance that the problem is simply unsolvable due to the characteristics of your data and business? This isn't a recipe for disaster, it's a cookbook for someone looking to prepare a twelve course fucking catastrophe.

How about you _remain competitive_ by _fixing your shit_? I've met a lead data scientist with access to hundreds of thousands of sensitive customer records who is allowed to keep their password in a text file on their desktop, and you're worried that customers are best served by using AI to improve security through some mechanism that you haven't even come up with yet? You sound like an _asshole_ and I'm going to kick you in the jaw until, to the relief of everyone, a doctor will have to wire it shut, giving us ten seconds of blessed silence where we can _solve actual problems_.

## III. We've Already Seen Extensive Gains From-

When I was younger, I read R.A Salvatore's classic fantasy novel, _The Crystal Shard_. There is a scene in it where the young protagonist, Wulfgar, challenges a barbarian chieftain to a duel for control of the clan so that he can lead his people into a war that will save the world. The fight culminates with Wulfgar throwing away his weapon, grabbing the chief's head with bare hands, and _begging_ the chief to surrender so that he does not need to crush a skull like an egg and become a murderer.

Well this is me. Begging you. To stop lying. I don't want to crush your skull, I really don't.

_But I will if you make me_.

Yesterday, I was shown [Scale's "2024 AI Readiness Report"](https://scale.com/ai-readiness-report#section-download). It has this chart in it:

![Scale Report.png](https://ludic.mataroa.blog/images/6687b89a.png)

How _stupid_ do you have to be to believe that only _8%_ of companies have seen failed AI projects? We can't manage this consistently with CRUD apps and people think that this number isn't laughable? _Some_ companies have seen benefits during the LLM craze, but not _92%_ of them. 34% of companies report that generative AI _specifically_ has been assisting with strategic decision making? What the actual fuck are you talking about? GPT-4 can't even write coherent Elixir, presumably because the dataset was too small to get it to the level that it's at for Python<sup id="fnref:3"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:3">3</a></sup>, and you're admitting that you outsource your decisionmaking to [_the thing that sometimes tells people to brew lethal toxins for their families to consume_](https://www.reddit.com/r/ChatGPT/comments/1diljf2/google_gemini_tried_to_kill_me/)? What does that even _mean_?

I don't believe you. No one with a brain believes you, and if your board believes what you just wrote on the survey then they should fire you. I finally understand why some of my friends feel that they _have_ to be in leadership positions, and it is because someone needs to wrench the reins of power from your lizard-person-claws before you drive us all collectively off a cliff, presumably insisting on the way down that the current crisis is best remedied by additional SageMaker spend.

A friend of mine was invited by a FAANG organization to visit the U.S a few years ago. Many of the talks were technical demos of impressive artificial intelligence products. Being a software engineer, he got to spend a little bit of time backstage with the developers, whereupon they revealed that _most of the demos were faked_. The products didn't work. They just hadn't solved some minor issues, such as _actually predicting the thing that they're supposed to predict_. Didn't stop them spouting absolute gibberish to a breathless audience for an hour though! I blame not the engineers, who probably tried to actually get the damn thing to work, but the lying blowhards who insisted that they must make the presentation or presumably be terminated<sup id="fnref:4"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:4">4</a></sup>.

Another friend of mine was reviewing software intended for emergency services, and the salespeople were not expecting someone handling purchasing in emergency services to be a hardcore programmer. It was this false sense of security that led them to _accidentally reveal that the service was ultimately just some dude in India_. Listen, _I_ would just be some random dude in India if I swapped places with some of my cousins, so I'm going to choose to take that personally and point out that _using the word AI as some roundabout way to sell the labor of people that look like me to foreign governments_ is fucked up, you're an unethical monster, and that if you continue to `try { thisBullshit(); }` you are going to `catch (theseHands)`

## IV. But We Must Prepare For The Future Of-

I'm going to ask ChatGPT how to prepare a garotte and then I am going to strangle you with it, and you will simply have to _pray_ that I roll the 10% chance that it freaks out and tells me that a garotte should consist entirely of paper mache and malice.

I see executive after executive discuss how they need to immediately roll out generative AI in order to prepare the organization for the future of work. Despite all the speeches sounding exactly the same, I know that they have rehearsed extensively, because they manage to move their hands, speak, and avoid drooling, all at the same time!

Let's talk seriously about this for a second.

I am _not_ in the equally unserious camp that generative AI does not have the potential to drastically change the world. It clearly does. When I saw the early demos of GPT-2, while I was still at university, I was half-convinced that they were faked somehow. I remember being wrong about that, and that is why I'm no longer as confident that I know what's going on.

However, I _do_ have the technical background to understand the core tenets of the technology, and it seems that we are heading in one of three directions.

The first is that we have some sort of intelligence explosion, where AI recursively self-improves itself, and we're all harvested for our constituent atoms because a market algorithm works out that humans can be converted into _gloobnar_, a novel epoxy which is in great demand amongst the aliens the next galaxy over for fixing their equivalent of coffee machines. It may surprise some readers that I am open to the possibility of this happening, but I have always found the arguments reasonably sound. However, defending the planet is a _whole other thing_, and I am not even convinced it is possible. In any case, you will be surprised to note that I am not tremendously concerned with the company's bottom line in this scenario, so we won't pay it any more attention.

A second outcome is that it turns out that the current approach does not scale in the way that we would hope, for myriad reasons. There isn't enough data on the planet, the architecture doesn't work the way we'd expect, the thing just stops getting smarter, context windows are a limiting factor forever, etc. In this universe, _some_ industries will be heavily disrupted, such as customer support.

In the case that the technology continues to make incremental gains like this, your company does not need generative AI for the sake of it. You will know _exactly_ why you need it if you do, indeed, need it. An example of something that has actually benefited me is that I keep track of my life administration via [Todoist](https://todoist.com/), and Todoist has a feature that allows you to convert filters on your tasks from natural language into their in-house filtering language. Tremendous! It saved me learning a system that I'll use once every five years. I was actually happy about this, and it's a real edge over other applications. But if you _don't have a use case_ then having this sort of broad capability is not actually very useful. The only thing you should be doing is _improving your operations and culture_, and that will give you the ability to use AI if it ever becomes relevant. Everyone is talking about Retrieval Augmented Generation, but most companies don't actually _have_ any internal documentation worth retrieving. Fix. Your. Shit.

The _final_ outcome is that these fundamental issues are addressed, and we end up with something that actually actually _can_ do things like replace programming as we know it today, or be broadly identifiable as general intelligence.

In the case that generative AI goes on some rocketship trajectory, _building random chatbots will not prepare you for the future_. Is that clear now? Having your team type in `import openai` does not mean that you are at the cutting-edge of artificial intelligence no matter how desperately you embarrass yourself on LinkedIn and at pathetic borderline-bribe award ceremonies from the malign Warp entities that sell you enterprise software<sup id="fnref:5"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:5">5</a></sup>. Your business will be disrupted _exactly as hard as it would have been_ if you had done nothing, and much worse than it would have been if you just got your fundamentals right. Teaching your staff that they can get ChatGPT to write emails to stakeholders is _not going to allow the business to survive this_. If we thread the needle between moderate impact and asteroid-wiping-out-the-dinosaurs impact, everything will be _changed forever_ and your tepid preparations will have all the impact of an ant bracing itself _very hard_ in the shadow of a towering tsunami.

If another stupid motherfucker asks me to try and implement LLM-based code review to "raise standards" instead of actually teaching people a shred of discipline, I am going to study enough judo to throw them into the goddamn sun.

I cannot emphasize this enough. You either need to _be on the absolute cutting-edge and producing novel research_, or you should be doing exactly what you were doing five years ago with minor concessions to incorporating LLMs. _Anything in the middle ground does not make any sense_ unless you actually work in the rare field where your industry is being _totally disrupted right now_.

## V. But Everyone Says They're Usi-

Can you imagine how much government policy is actually written by ChatGPT before a bored administrator goes home to touch grass? How many departments are just LLMs talking to each other in circles as people sick of the bullshit just paste their email exchanges into long-running threads? I _guarantee_ you that a doctor within ten kilometers of me has misdiagnosed a patient because they slapped some symptoms into a chatbot.

What are we _doing_ as a society?

___

An executive at an institution that provides students with important credentials, used to verify suitability for potentially lifesaving work and immigration law, asked me if I could detect students cheating. I was going to say "No, probably not"... but I had a suspicion, so I instead said "I might be able to, but I'd estimate that upwards of 50% of the students are currently cheating which would have some serious impacts on the bottom line as we'd have to suspend them. Should I still investigate?"

We haven't spoken about it since.

___

I asked a mentor, currently working in the public sector, about a particularly perplexing exchange that I had witnessed.

> Me: Serious question: do people actually believe stories that are so transparently stupid, or is it mostly an elaborate bit (that is, there is at least a voice of moderate loudness expressing doubt internally) in a sad attempt to get money from AI grifters?
> 
> Them: I shall answer this as politically as I can... there are those that have drunk the kool-aid. There are those that have not. And then there are those that are trying to mix up as much kool-aid as possible. I shall let you decide who sits in which basket.

I've decided, and while I can't distinguish between the people that are slamming the kool-aid like it's a weapon and the people producing it in industrial quantities, I know that I am going to get _a few of them_ before the authorities catch me - if I'm lucky, they'll waste a few months asking an LLM where to look for me.

___

When I was out on holiday in Fiji, at the last resort breakfast, a waitress brought me a form which asked me if I'd like to sign up for a membership. It was totally free and would come with free stuff. Everyone in the restaurant is signing immediately. I glance over the terms of service, and it reserves the right to use any data I give them to train AI models, and that they reserved the right to share those models with an unspecified number of companies in their conglomerate.

I just want to eat my pancakes in peace, you sick fucks.

## VI.

The crux of my raging hatred is not that I _hate_ LLMs or the generative AI craze. I had my fun with Copilot before I decided that it was making me stupider - it's impressive, but not actually _suitable_ for anything more than churning out boilerplate. Nothing wrong with that, but it did not end up being the crazy productivity booster that I thought it would be, because _programming is designing_ and these tools aren't good enough (yet) to assist me with this seriously.

No, what I hate is the people who have latched onto it, like so many trailing leeches, bloated with blood and wriggling blindly. Before it was unpopular, they were the ones that loved discussing the potential of blockchain for the business. They were the ones who [breathlessly discussed the potential of 'quantum'](https://ludic.mataroa.blog/blog/an-empty-hall-of-smiling-assassins/) when I last attended a conference, despite clearly not having any idea what the fuck that even means. As I write this, I have just realized that I have an image that describes the link between these fields perfectly.

I was reading an article last week, and a little survey popped up at the bottom of it. It was for security executives, but on a whim I clicked through quickly to see what the questions were.

![security_grift.png](https://ludic.mataroa.blog/images/d267ff69.png)

There you have it - what are you most interested in, dear leader? Artificial intelligence, the blockchain, or quantum computing?<sup id="fnref:6"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:6">6</a></sup> They know exactly what their target market is - people who have been given power of _other people's money_ because they've learned how to smile at everything, and know that you can print money by hitching yourself to the next speculative bandwagon. No competent person in security that I know - that is, working day-to-day cybersecurity as opposed to an institution dedicated to bleeding-edge research - cares about any of this. They're busy trying to work out if the firewalls are configured correctly, or if the organization is committing passwords to their repositories. Yes, someone needs to figure out what the implications of quantum computing are for cryptography, but I _guarantee_ you that it is not Synergy Greg, who does not have any skill that you can identify other than talking very fast and increasing headcount. Synergy Greg should not be consulted on any important matters, ranging from machine learning operations to tying shoelaces quickly. The last time I spoke to one of the many avatars of Synergy Greg, he insisted that I should invest most of my money into a cryptocurrency called Monero, because "most of these coins are going to zero but the one is going to one". _This is the face of corporate AI._ Behold its ghastly visage and balk, for it has eyes bloodshot as a demon and is pretending to enjoy cigars.

My consultancy has three _pretty good_ data scientists - in fact, two of them could probably reasonably claim to be amongst the best in the country outside of groups doing experimental research, though they'd be too humble to say this. Despite this _we don't sell AI services_ of any sort. The market is so distorted that it's _almost_ as bad as dabbling in the crypto space. It isn't as bad, meaning that I haven't yet reached the point where I assume that anyone who has ever typed in `import tensorflow` is a scumbag, but _we're well on our way there_.

This entire class of person is, to put it simply, abhorrent to right-thinking people. They're an embarrassment to people that are actually making advances in the field, a disgrace to people that know how to sensibly use technology to improve the world, and are also a bunch of tedious know-nothing bastards that should be thrown into Thought Leader Jail until they've learned their lesson, a prison I'm fundraising for. Every morning, a figure in a dark hood<sup id="fnref:7"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:7">7</a></sup>, whose voice rasps like the etching of a tombstone, spends sixty minutes giving a TedX talk to the jailed managers about how the institution is revolutionizing corporal punishment, and then reveals that the innovation is, as it has been every day, kicking you in the stomach very hard. I am disgusted that my chosen profession brings me so close to these people, and that's why I study so hard - I am seized by the desperate desire to never have their putrid syllables befoul my ears ever again, and must flee to the company of the righteous, who contribute to OSS and think that talking about Agile all day is an exercise for aliens that read a book on human productivity.

I just got back from a trip to a substantially less developed country, and really _living_ in a country, even for a little bit, where I could _see_ how many lives that money could improve, all being poured down the Microsoft Fabric drain, it just grinds my gears like you wouldn't believe. I swear to God, I am going to study, write, network, and otherwise _apply force to the problem_ until those resources are going to a place where they'll accomplish something for society instead of some grinning clown's wallet.

## VII. Oh, So You're One Of Those AI Pessi-

With God as my witness, you grotesque simpleton, if you don't _personally write machine learning systems_ and you open your mouth about AI one more time, I am going to mail you a brick and a piece of paper with a prompt injection telling you to bludgeon yourself in the face with it, then just sit back and wait for you to load it into ChatGPT because you probably can't read unassisted anymore.

___

### PS

While many new readers are here, you may also enjoy ["I Will Fucking Dropkick You If You Use That Spreadsheet"](https://ludic.mataroa.blog/blog/i-will-fucking-dropkick-you-if-you-use-that-spreadsheet/), ["I Will Fucking Haymaker You If You Mention Agile Again"](https://ludic.mataroa.blog/blog/i-will-fucking-haymaker-you-if-you-mention-agile-again/), or otherwise enjoy these [highlighted posts](https://ludic.mataroa.blog/hits/). And I have a podcast where I talk with my friends about tech stuff honestly, titled "[Does A Frog Have Scorpion Nature"](https://podcasts.apple.com/au/podcast/does-a-frog-have-scorpion-nature/id1737204926). Hope you enjoyed!

It has also been suggested that I am crazy for not telling people to reach out with interesting work at the end of every post. So here it is! I am available for reader mail and work at ludicity.hackernews@gmail.com.

Posts may be slower than usual for the upcoming weeks or months, as I am switching to a slower but more consistent writing schedule, more ambitious pieces, studying, working on what will hopefully be my first talk<sup id="fnref:8"><a href="https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/#fn:8">8</a></sup>, putting together a web application that users may have some fun with, and participating in my first real theater performance. Hope you enjoyed, and as always, thanks for reading.
